# Week 7 â€” Applied Project Workshop
Focus: teams select domain problem  
Instructor check-ins

> This week you transition from learning concepts to applying them in your capstone project. Strong project planning now saves countless hours later.
---

## Project Objectives
Feasible, ethical, useful

> Define objectives that are feasible (can you actually build this?), ethical (should you build this?), and useful (does anyone want this?).
---

## Problem Framing
Users, pain points, scope

![](images/diagram_discovery_workflow.png)

> Problem framing identifies specific users, their pain points, and realistic scope. Vague problems lead to failed projects.
---

## Success Metrics
What does good look like?

> Success metrics answer 'what does good look like?' with measurable outcomes, not just technical metrics but actual user value.
---

## Data Plan
Sources, access, privacy

> Your data plan specifies sources, how to access them, and privacy considerations. Data problems are the most common reason ML projects fail.
---

## Method Outline
Baselines, main approach, evaluation

![](images/diagram_research_workflow.png)

> Method outline includes baselines (simple approaches), your main approach, and evaluation strategy. Always start simple before trying complex methods.
---

## Architecture Sketch
Components and interfaces

> Architecture sketches show components (data, model, API, UI) and how they connect. This helps identify potential problems early.
---

## Risks and Assumptions
Unknowns, dependencies, mitigations

> Risk and assumption tracking forces you to acknowledge what could go wrong and what you're assuming is true. Test your riskiest assumptions first.
---

## Milestones
This week, next week, final

> Milestones break work into weekly chunks with concrete deliverables. 'Make progress on the model' is not a milestone, 'Train baseline model and measure accuracy' is.
---

## Team Roles
Who owns what?

> Clear team roles prevent duplicated work and gaps where nobody takes responsibility. Define who owns what.
---

## Check-in 1
Progress, blockers, decisions

> First check-in focuses on progress, blockers, and decisions made. This is a time to ask for help or adjust scope.
---

## Check-in 2
Risks, scope, open questions

> Second check-in addresses new risks, scope adjustments, and open questions. Projects evolve - planned adjustments beat crisis pivots.
---

## Demo Rehearsal Plan
Story, flow, backup plan

> Demo rehearsal planning includes your narrative story, presentation flow, and backup plan if live demos fail (they often do).
---

## Reflection Prompt
What's the riskiest assumption? How to test fast?

> Identify your riskiest assumption and design a quick test. For example, if you assume data quality is good, spot check 100 examples before investing in complex models.
---

## Stakeholder Interviews
Identify users  
Capture needs and constraints

> Stakeholder interviews with potential users reveal needs and constraints you wouldn't discover otherwise. Five good interviews beats one hundred surveys.
---

## Hypothesis and Experiment
Define falsifiable hypotheses  
Design quick tests

> Define falsifiable hypotheses and experiments that could prove them wrong. 'Users will like this' is not testable, 'Users will complete task in under 2 minutes' is.
---

## Data Ethics Check
Consent, privacy, sensitive fields, retention plan

> Data ethics checklist covers consent (do people know their data is used?), privacy (is sensitive information protected?), sensitive fields (removing identifiers), and retention plans.
---

## Evaluation Plan
Offline metrics + simple user task success

> Evaluation plan combines offline metrics (model accuracy) with simple user task success (can they actually accomplish their goal?).
---

## Acceptance Criteria
"Done" definition for MVP and demo

> Acceptance criteria define 'done' for both MVP (minimum viable product) and demo. Being specific prevents endless feature creep.
---

## Kanban Snapshot
Backlog, in-progress, blocked, done

> Kanban snapshot shows work status: backlog (not started), in-progress (being worked on), blocked (waiting on something), done (completed).
---

## Risk Burndown
Track and retire top 3 risks weekly

> Risk burndown tracking your top 3 risks weekly, retiring them as they're addressed or accepting them if mitigation isn't feasible.
---

## Integration Plan
Data sources, APIs, auth  
Test environments

> Integration plan identifies data sources, APIs, authentication requirements, and test environments separate from production.
---

## Observability Plan
Minimal logs/metrics for demo day

> Observability planning defines minimal logs and metrics for demo day so you can debug issues and demonstrate system behavior.
---

## Test Plan
Unit tests for prompts/APIs  
Manual QA checklist

> Test plan includes unit tests for critical functions (especially prompts and API calls) and manual QA checklist for integration testing.
---

## Contingency Plan
Offline demo path  
Pre-recorded backup

> Contingency planning means having an offline demo option and pre-recorded backup in case internet fails or services go down during presentations.
---

## Rehearsal Checklist
Timing, roles, handoffs, devices, adapters

> Rehearsal checklist covers timing (practice your 5 minutes), roles (who presents what), handoffs between speakers, and physical setup (devices, adapters, connections).
---

## Submission Checklist
Repo, README, setup, dataset notes, ethics notes

> Submission checklist ensures your repository has readable code, clear README explaining setup, sample dataset, usage notes, and ethical considerations documented.
---

## Reading List
Lightweight project management and MVP playbooks

> Readings on lightweight project management and MVP development help you stay focused on delivering a working demo rather than perfect software.