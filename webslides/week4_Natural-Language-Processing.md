# Week 4
# Natural Language Processing

---

## Why Language Matters

Most data is text  
NLP turns language into measurable structure

---

## Tokenization

Break sentences into tokens  
Use WordPiece or Byte-Pair Encoding for subwords

---

## Bag of Words

Represent frequency of words in documents  
Ignores order but reveals importance

---

## TF-IDF

Highlights unique terms by weighting rare words higher

---

## Embeddings

Map words into dense vectors where meaning is geometric  
Similar words are close in cosine space

---

## Cosine Similarity

Measures angle between vectors  
Used for search and clustering

---

## Sentiment Analysis Example

Use VADER or a transformer  
Plot positive, negative, and neutral distributions

---

## Vector Stores and Retrieval

Store embeddings in databases like FAISS or Chroma  
Retrieve similar documents for context-aware AI

---

## Summary

NLP converts meaning into math  
Similarity and context drive understanding

