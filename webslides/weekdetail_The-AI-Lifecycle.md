# Week 10
# The AI Lifecycle

> This slide explores an important concept in applied AI. Understanding this material will help you make better decisions when evaluating opportunities and challenges in your field.
---

## From idea to monitoring — how responsible AI gets built and maintained

> This slide explores an important concept in applied AI. Understanding this material will help you make better decisions when evaluating opportunities and challenges in your field.
---

## The Core Idea

AI isn't a single project step.  
It's a loop — idea, build, deploy, monitor, improve.  
Governance and feedback close the loop

> This slide explores an important concept in applied AI. Understanding this material will help you make better decisions when evaluating opportunities and challenges in your field.
---

## The Lifecycle Phases

Ideation — define business need and success metrics.  
Data Prep — gather, clean, and label data.  
Modeling — experiment, test, and validate models.  
Deployment — integrate into systems.  
Monitoring — track accuracy, drift, and risk.  
Feedback & Improvement — retrain and redeploy

> The AI lifecycle encompasses ideation, data preparation, modeling, deployment, monitoring, and iteration. Each stage presents distinct challenges requiring different skills, tools, and organizational capabilities.
---

## Example

Retail company wants to predict demand.  
They define success (reduce waste by 10%), prepare data, train a model, deploy it, and monitor error weekly.  
When seasonality shifts, they retrain

> Concrete examples illustrate how abstract concepts apply in practice. Studying both successes and failures reveals patterns worth emulating or avoiding.
---

## Why Monitoring Matters

Models decay.  
Data drifts.  
Regular review catches small errors before they become costly failures

> Understanding why concepts matter helps you apply them appropriately. This context prevents cargo-cult adoption of practices that don't fit your situation.
---

## Governance Integration

Each phase links to governance:  
Ideation → ethics review.  
Data prep → bias testing.  
Deployment → approval.  
Monitoring → audit logs

> AI governance establishes policies, processes, oversight mechanisms, and accountability for responsible deployment. This includes defining acceptable use, review procedures, incident response, and continuous monitoring.
---

## Common Failures

Skipping testing.  
No owner for retraining.  
Ignoring model drift.  
Lifecycle discipline prevents those mistakes

> Risk assessment identifies what could go wrong, how likely it is, and how serious the consequences would be. Prioritize mitigations for your highest-impact risks.
---

## Summary

AI success depends on process.  
A clear lifecycle turns AI from an experiment into infrastructure

> This slide explores an important concept in applied AI. Understanding this material will help you make better decisions when evaluating opportunities and challenges in your field.