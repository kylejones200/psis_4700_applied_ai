# Week 4 — Ethics and Policy (STEW-style Lesson Plan)

- Audience: Adult undergraduates (hybrid/online)
- Duration: 3 hours contact + 1–2 hours prep

## Overview
Examine bias, privacy, transparency, safety, and emerging policy frameworks (NIST/OECD). Practice identifying risks and proposing safeguards.

## Learning Objectives
- Describe core Responsible AI principles in plain language.
- Identify sources of bias and propose mitigation strategies.
- Summarize key ideas from NIST AI RMF and OECD AI principles.
- Draft a concise safeguard plan for a selected use-case.

## Materials & Tools
- Slides: `slides_intro/week-04-ethics-policy.md`
- Handout: risk assessment template (likelihood × impact)
- Short excerpts: NIST AI RMF overview; OECD AI principles

## Key Vocabulary
- Bias, fairness, transparency, privacy, safety, red teaming, accessibility, risk assessment

## Prerequisites
- Weeks 1–3 concepts; familiarity with applications and metrics

## Schedule (3:00)
- 0:00–0:10 Recap & goals
- 0:10–0:30 Mini-lecture: principles and common pitfalls
- 0:30–0:55 Case vignette: identify risks and affected stakeholders
- 0:55–1:05 Break
- 1:05–1:30 NIST/OECD guided reading (jigsaw or pairs)
- 1:30–2:05 Group work: draft safeguards (data, model, deployment)
- 2:05–2:35 Mini-debate: tradeoffs in one safeguard choice
- 2:35–2:55 Share-outs; instructor synthesis
- 2:55–3:00 Exit ticket

## Warm-Up (10 min)
- Prompt: “Who is impacted by your chosen use-case beyond the direct user?”

## Core Activities
- Stakeholder mapping; risk identification and prioritization.
- Reading circle on NIST/OECD; groups summarize key takeaways.
- Draft safeguard plan covering data governance, model behavior, and operations.

## Differentiation
- Provide non-technical and technical examples of safeguards.
- Offer optional deep-dive on measurement of fairness metrics.

## Assessment
- Formative: Exit ticket naming one concrete safeguard and rationale.
- Summative: 1-page risk assessment + safeguard plan.

## Homework/Prep (60–90 min)
- Finalize safeguard plan; short reflection on remaining risks.

## Instructor Notes
- Keep examples grounded; avoid abstract ethics without application.
- Encourage specific, testable safeguards and clear owners.

## Accessibility & Inclusion
- Provide readings with accessible formatting; ensure slide contrast.

## References
- NIST AI RMF (Map-Measure-Manage); OECD AI Principles; Model Cards; Datasheets.
